{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "599f0abd-bf68-413f-9f64-3c4a4a29ec4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /databricks/python3/lib/python3.12/site-packages (2.2.3)\nCollecting snowflake-snowpark-python[pandas]\n  Downloading snowflake_snowpark_python-1.40.0-py3-none-any.whl.metadata (170 kB)\nRequirement already satisfied: setuptools>=40.6.0 in /usr/local/lib/python3.12/dist-packages (from snowflake-snowpark-python[pandas]) (74.0.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from snowflake-snowpark-python[pandas]) (0.45.1)\nCollecting snowflake-connector-python<4.0.0,>=3.17.0 (from snowflake-snowpark-python[pandas])\n  Downloading snowflake_connector_python-3.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (74 kB)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python[pandas]) (4.12.2)\nRequirement already satisfied: pyyaml in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python[pandas]) (6.0.2)\nRequirement already satisfied: cloudpickle!=2.1.0,!=2.2.0,<=3.1.1,>=1.6.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python[pandas]) (3.0.0)\nRequirement already satisfied: protobuf<6.32,>=3.20 in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python[pandas]) (5.29.4)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.12/site-packages (from snowflake-snowpark-python[pandas]) (2.9.0.post0)\nCollecting tzlocal (from snowflake-snowpark-python[pandas])\n  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2.1.3)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil->snowflake-snowpark-python[pandas]) (1.16.0)\nCollecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas])\n  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: boto3>=1.24 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (1.36.2)\nRequirement already satisfied: botocore>=1.24 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (1.36.3)\nRequirement already satisfied: cffi<2.0.0,>=1.9 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (1.17.1)\nRequirement already satisfied: cryptography>=3.1.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (43.0.3)\nCollecting pyOpenSSL<26.0.0,>=22.0.0 (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas])\n  Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: pyjwt<3.0.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (2.10.1)\nRequirement already satisfied: requests<3.0.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (2.32.3)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (24.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (2025.1.31)\nRequirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.12/dist-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (3.18.0)\nRequirement already satisfied: sortedcontainers>=2.4.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (2.4.0)\nRequirement already satisfied: platformdirs<5.0.0,>=2.6.0 in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (3.10.0)\nCollecting tomlkit (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas])\n  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: pyarrow in /databricks/python3/lib/python3.12/site-packages (from snowflake-connector-python[pandas]<4.0.0,>=3.17.0; extra == \"pandas\"->snowflake-snowpark-python[pandas]) (19.0.1)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /databricks/python3/lib/python3.12/site-packages (from boto3>=1.24->snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (0.11.3)\nRequirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /databricks/python3/lib/python3.12/site-packages (from botocore>=1.24->snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (2.3.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas]) (2.21)\nCollecting cryptography>=3.1.0 (from snowflake-connector-python<4.0.0,>=3.17.0->snowflake-snowpark-python[pandas])\n  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\nINFO: pip is looking at multiple versions of cryptography to determine which version is compatible with other requirements. This could take a while.\n  Downloading cryptography-46.0.2-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n  Downloading cryptography-46.0.1-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n  Downloading cryptography-46.0.0-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\nDownloading snowflake_connector_python-3.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m111.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading snowflake_snowpark_python-1.40.0-py3-none-any.whl (1.8 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m103.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\nDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\nDownloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\nDownloading cryptography-46.0.0-cp311-abi3-manylinux_2_34_x86_64.whl (4.6 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/4.6 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.6/4.6 MB\u001B[0m \u001B[31m156.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\nInstalling collected packages: asn1crypto, tzlocal, tomlkit, cryptography, pyOpenSSL, snowflake-connector-python, snowflake-snowpark-python\n  Attempting uninstall: cryptography\n    Found existing installation: cryptography 43.0.3\n    Not uninstalling cryptography at /databricks/python3/lib/python3.12/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-77abb302-d2ec-452b-ba8d-31c2222f7936\n    Can't uninstall 'cryptography'. No files were found to uninstall.\nSuccessfully installed asn1crypto-1.5.1 cryptography-46.0.0 pyOpenSSL-25.3.0 snowflake-connector-python-3.18.0 snowflake-snowpark-python-1.40.0 tomlkit-0.13.3 tzlocal-5.3.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install \"snowflake-snowpark-python[pandas]\" pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3ae6d16-970f-47b2-a4dc-a281d57e2194",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#restart kernel \n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94cbcac6-3995-41b3-8e37-e2a73c58f4db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# snowpark_ingest.py\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.types import StructType, StructField, StringType, DateType, IntegerType, DoubleType\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------- CONFIG -------------\n",
    "connection_parameters = {\n",
    "  \"account\": \"ioijmaj-rr68892.snowflakecomputing.com>\",         # e.g. xy12345.east-us-2.azure\n",
    "  \"user\": \"nikitha\",\n",
    "  \"password\": \"Nikitha@21122003\",                # or use key-pair auth\n",
    "  \"role\": \"ACCOUNTADMIN\",\n",
    "#   \"warehouse\": \"<WAREHOUSE>\",\n",
    "  \"database\": \"RETAIL_DB\",\n",
    "  \"schema\": \"SALES\"\n",
    "}\n",
    "STAGE_PATH = \"@sales_stage_azure\"  # or sales_stage_sas\n",
    "CSV_FILE_PREFIX = \"incoming/2025/10/\"  # if you use subfolders\n",
    "# -----------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d13a7c49-b7a3-4a88-a22b-4ecf2b79d982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:139)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:139)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:136)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:192)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:720)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:440)\n",
       "\tat scala.Option.getOrElse(Option.scala:201)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:440)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:759)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:80)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:80)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:80)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:80)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:731)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequest$1(Chauffeur.scala:938)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$handleDriverRequests$2(Chauffeur.scala:965)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionContext(Chauffeur.scala:170)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionTags(Chauffeur.scala:170)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.recordOperationWithResultTags(Chauffeur.scala:170)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:964)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequests(Chauffeur.scala:1015)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:826)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:731)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:727)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:722)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:189)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:186)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$5(ServerBackend.scala:175)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:23)\n",
       "\tat com.databricks.rpc.ServerBackend.executeWithLogging$1(ServerBackend.scala:148)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:175)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:997)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:917)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:557)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:522)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:1096)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:1096)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1058)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1039)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$39(ActivityContextFactory.scala:406)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:406)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:417)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:139)",
        "\tat scala.Option.getOrElse(Option.scala:201)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:139)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:136)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:192)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:720)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:440)",
        "\tat scala.Option.getOrElse(Option.scala:201)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:440)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:759)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:80)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:80)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:80)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:80)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:731)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequest$1(Chauffeur.scala:938)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$handleDriverRequests$2(Chauffeur.scala:965)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionContext(Chauffeur.scala:170)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionTags(Chauffeur.scala:170)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.recordOperationWithResultTags(Chauffeur.scala:170)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:964)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequests(Chauffeur.scala:1015)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:826)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:731)",
        "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:727)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:722)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:189)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:215)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:186)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$5(ServerBackend.scala:175)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:23)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:127)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:108)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:23)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:23)",
        "\tat com.databricks.rpc.ServerBackend.executeWithLogging$1(ServerBackend.scala:148)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:175)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:997)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:917)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:557)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:522)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:1096)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:1096)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1058)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1039)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$39(ActivityContextFactory.scala:406)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:63)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:406)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:417)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:80)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:78)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:75)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "# Read CSVs from stage (wildcard)\n",
    "csv_path = f\"{STAGE_PATH}/{CSV_FILE_PREFIX}*.csv\"\n",
    "\n",
    "# If header present, Snowpark supports session.read.option\n",
    "df = session.read.option(\"SKIP_HEADER\", 1).option(\"FIELD_DELIMITER\", \",\").csv(csv_path)\n",
    "\n",
    "# Inspect schema & basic transformations\n",
    "# Example: rename columns to match table; adjust based on your CSV columns\n",
    "# Suppose CSV columns: SalesID,SaleDate,ProductID,ProductName,StoreID,Region,Quantity,Price,TotalAmount\n",
    "\n",
    "# Standardize column names\n",
    "df = df.to_df(\"sales_id\",\"sale_date\",\"product_id\",\"product_name\",\"store_id\",\"region\",\"quantity\",\"price\",\"total_amount\")\n",
    "\n",
    "# Type cast\n",
    "from snowflake.snowpark.functions import to_date, col\n",
    "df = df.with_column(\"sale_date\", to_date(col(\"sale_date\"), \"YYYY-MM-DD\")) \\\n",
    "       .with_column(\"quantity\", col(\"quantity\").cast(\"INTEGER\")) \\\n",
    "       .with_column(\"price\", col(\"price\").cast(\"DOUBLE\")) \\\n",
    "       .with_column(\"total_amount\", col(\"total_amount\").cast(\"DOUBLE\"))\n",
    "\n",
    "# Remove duplicates (optional)\n",
    "df = df.drop_duplicates([\"sales_id\"])\n",
    "\n",
    "# Write into Snowflake table (append)\n",
    "df.write.mode(\"append\").save_as_table([\"RETAIL_DB\", \"SALES\", \"MONTHLY_SALES\"])\n",
    "\n",
    "print(\"Ingest complete.\")\n",
    "session.close()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Case scenerio",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}